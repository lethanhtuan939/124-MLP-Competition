{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Competition 124 - Lê Thanh Tuấn - 21115053120158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import initializers\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### config seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(train_path, target_path, test_path, test_size=0.2, random_state=42):\n",
    "    X_train = pd.read_csv(train_path, low_memory=False).drop(columns=['ID'], errors='ignore')\n",
    "    y_train = pd.read_csv(target_path)['TARGET']\n",
    "    X_test = pd.read_csv(test_path, low_memory=False)\n",
    "    \n",
    "    test_ids = X_test.pop('ID') if 'ID' in X_test.columns else np.arange(len(X_test))\n",
    "\n",
    "    for df in [X_train, X_test]:\n",
    "        if 'tradeTime' in df.columns:\n",
    "            df['tradeTime'] = pd.to_datetime(df['tradeTime'], errors='coerce')\n",
    "        \n",
    "        df.replace({\n",
    "            'elevator': {1: 'has elevator', 0: 'no elevator'},\n",
    "            'subway': {1: 'has subway', 0: 'no subway'},\n",
    "            'buildingStructure': {1: 'unknown', 2: 'mixed', 3: 'brick and wood', 4: 'concrete', 5: 'steel', 6: 'steel-concrete composite'},\n",
    "            'renovationCondition': {1: 'other', 2: 'rough', 3: 'Simplicity', 4: 'hardcover'},\n",
    "            'buildingType': {1: 'tower', 2: 'bungalow', 3: 'combination of plate and tower', 4: 'plate'}\n",
    "        }, inplace=True)\n",
    "        \n",
    "        if 'constructionTime' in df.columns:\n",
    "            df['constructionTime'] = pd.to_numeric(df['constructionTime'], errors='coerce')\n",
    "\n",
    "        if 'floor' in df.columns:\n",
    "            df['floor'] = df['floor'].astype(str).str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "\n",
    "        # Convert Lat and Lng to numeric and calculate distance to the capital\n",
    "        df['Lat'] = pd.to_numeric(df['Lat'], errors='coerce')\n",
    "        df['Lng'] = pd.to_numeric(df['Lng'], errors='coerce')\n",
    "\n",
    "        capital_Lng = np.radians(116.4074)\n",
    "        capital_Lat = np.radians(39.9042)\n",
    "        df['distanceToCapital'] = np.arccos(\n",
    "            np.sin(np.radians(df['Lat'])) * np.sin(capital_Lat) +\n",
    "            np.cos(np.radians(df['Lat'])) * np.cos(capital_Lat) *\n",
    "            np.cos(capital_Lng - np.radians(df['Lng']))\n",
    "        ) * 6371.0088  # Earth's radius in kilometers\n",
    "\n",
    "        if 'tradeTime' in df.columns and 'constructionTime' in df.columns:\n",
    "            df['ageOfBuilding'] = df['tradeTime'].dt.year - df['constructionTime']\n",
    "\n",
    "    # Handle missing values for 'elevator' and 'subway'\n",
    "    for df in [X_train, X_test]:\n",
    "        df['elevator'] = df['elevator'].fillna(0)\n",
    "        df['subway'] = df['subway'].fillna(0)\n",
    "\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Align columns between X_train and X_test to avoid mismatches\n",
    "    common_cols = X_train.columns.intersection(X_test.columns)\n",
    "    X_train, X_test = X_train[common_cols], X_test[common_cols]\n",
    "    \n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = PowerTransformer()\n",
    "\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(imputer.fit_transform(X_train)), columns=common_cols)\n",
    "    X_test = pd.DataFrame(scaler.transform(imputer.transform(X_test)), columns=common_cols)\n",
    "\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train, y_train, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train_split, X_val_split, y_train_split, y_val_split, X_test, test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(input_shape,), kernel_initializer=initializers.HeNormal(seed=42)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu', kernel_initializer=initializers.HeNormal(seed=42)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu', kernel_initializer=initializers.HeNormal(seed=42)),\n",
    "        Dense(1, kernel_initializer=initializers.HeNormal(seed=42))\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile and train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train_mlp(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=64):\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(y_true, y_pred, model_name=\"Model\"):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{model_name} RMSE: {rmse}\")\n",
    "    return rmse\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_val, y_val):\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20, \n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_val = rf_model.predict(X_val)\n",
    "    val_rmse = print_rmse(y_val, y_pred_val, model_name=\"RandomForest\")\n",
    "    \n",
    "    return rf_model, val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save output (submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(y_pred, test_ids, filename='Latest_submission.csv'):\n",
    "    submission = pd.DataFrame({\n",
    "        \"ID\": test_ids,\n",
    "        \"TARGET\": y_pred\n",
    "    })\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\Anaconda\\envs\\ai_class\\lib\\site-packages\\numpy\\core\\_methods.py:247: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "d:\\ProgramFiles\\Anaconda\\envs\\ai_class\\lib\\site-packages\\numpy\\core\\_methods.py:236: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest RMSE: 53.35641146058034\n",
      "Epoch 1/50\n",
      "3189/3189 [==============================] - 8s 2ms/step - loss: 8772.5723 - val_loss: 3910.9028 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 5775.0649 - val_loss: 3348.7214 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 5192.0151 - val_loss: 7117.9937 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 4991.5068 - val_loss: 10288.2109 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 4998.6626 - val_loss: 9924.1709 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 4565.2534 - val_loss: 5583.8296 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "3189/3189 [==============================] - 7s 2ms/step - loss: 4474.7705 - val_loss: 4443.5601 - lr: 5.0000e-04\n",
      "Model saved successfully to 'weight/mlp_model.h5'.\n",
      "MLP with RF Feature RMSE: 57.86814782965359\n"
     ]
    }
   ],
   "source": [
    "X_train_split, X_val_split, y_train_split, y_val_split, X_test_scaled, test_ids = load_and_process_data(\n",
    "    'data/X_train.csv', 'data/y_train.csv', 'data/X_test.csv'\n",
    ")\n",
    "\n",
    "rf_model, rf_rmse = train_random_forest(X_train_split, y_train_split, X_val_split, y_val_split)\n",
    "\n",
    "# Use Random Forest predictions as a new feature for MLP\n",
    "rf_train_predictions = rf_model.predict(X_train_split).reshape(-1, 1)\n",
    "rf_val_predictions = rf_model.predict(X_val_split).reshape(-1, 1)\n",
    "rf_test_predictions = rf_model.predict(X_test_scaled).reshape(-1, 1)\n",
    "\n",
    "# Append RF predictions to training and validation sets\n",
    "X_train_split_with_rf = np.hstack((X_train_split, rf_train_predictions))\n",
    "X_val_split_with_rf = np.hstack((X_val_split, rf_val_predictions))\n",
    "X_test_with_rf = np.hstack((X_test_scaled, rf_test_predictions))\n",
    "\n",
    "# Build and train the improved MLP model using RandomForest predictions as an additional feature\n",
    "mlp_model = build_mlp_model(X_train_split_with_rf.shape[1])\n",
    "mlp_model = compile_and_train_mlp(mlp_model, X_train_split_with_rf, y_train_split, X_val_split_with_rf, y_val_split)\n",
    "\n",
    "mlp_model.save('weight/mlp_model.h5')\n",
    "print(\"Model saved successfully to 'weight/mlp_model.h5'.\")\n",
    "\n",
    "# Predict using the trained MLP model on the validation set\n",
    "y_pred_val_mlp = mlp_model.predict(X_val_split_with_rf).flatten()\n",
    "mlp_rmse = print_rmse(y_val_split, y_pred_val_mlp, model_name=\"MLP with RF Feature\")\n",
    "\n",
    "# Predict on the test set using the trained MLP model\n",
    "y_pred_test_mlp = mlp_model.predict(X_test_with_rf).flatten()\n",
    "\n",
    "save_submission(y_pred_test_mlp, test_ids, filename='Latest_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
